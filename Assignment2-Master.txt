Step 1:

Convert the csv file to tsv file.

Step 2: Clean

tr -d '\n' < Trump100k.txt > Trump100k_c.txt

Step 3: Make directory in HDFS

hdfs dfs -mkdir Twitter_Data_Dir

Step 4: Put cleaned file in directory

hadoop fs -put Trump100k_c.txt Twitter_Data_Dir

Step 5: Check if file was uploaded successfully

hadoop fs -ls Twitter_Data_Dir

Step 6:

**HIVE - Create new database**

CREATE DATABASE SentimentAnalysis_db;

Step 7:

**Hive -  Create new table **

CREATE TABLE IF NOT EXISTS SentimentAnalysis_db.Trump_10 (sr_no  int, id_str String, created_at String, text String, followers_count int, retweet_count int, tweet_tmstmp String, tweet_date String, tweet_time String, negative_score int, neutral_score int, positive_score int, compound_score int) COMMENT 'Creating table for twitter sentiment analysis'  ROW FORMAT DELIMITED FIELDS TERMINATED by '\t' STORED AS TEXTFILE;

Step 8:

**PIG - Load the cleaned data **

trump_pig_1 = LOAD 'Twitter_Data_Dir/Trump100k_c.txt' USING PigStorage('\t') AS (sr_no:int, id_str:chararray, created_at:chararray, text:chararray, followers_count:int, retweet_count:int, tweet_tmstmp:chararray, tweet_date:chararray, tweet_time:chararray, negative_score:int, neutral_score:int, positive_score:int, compound_score:int);

Step 9:

** Pig - store the data in table

STORE trump_pig_1 INTO 'SentimentAnalysis_db.Trump_10' USING org.apache.hive.hcatalog.pig.HCatStorer();

Step 10:

**Hive - Query to select duplicate entries with max retweet count **

select text, max(retweet_count), max(negative_sore), max(neutral_score), max(positive_score), max(compound_score), count(text) as cnt from [TableName] group by text
